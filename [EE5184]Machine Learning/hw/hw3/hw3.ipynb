{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_exp_name = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "\n",
    "# This is for the progress bar.\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import torchvision.models as models\n",
    "import Aentations as A\n",
    "from Aentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myseed = 459  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally, We don't need augmentations in testing and validation.\n",
    "# All we need here is to resize the PIL image and transform it into Tensor.\n",
    "test_tfm = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.CenterCrop(224, 224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# However, it is also possible to use augmentation in the testing phase.\n",
    "# You may use train_tfm to produce a variety of images and then test using ensemble methods\n",
    "train_tfm = A.Compose([\n",
    "    A.Resize(256, 256), # fit resnet34\n",
    "    A.CenterCrop(224, 224),\n",
    "    A.OneOf([\n",
    "        A.Blur(p = 0.2),\n",
    "        A.GaussianBlur(p = 0.2),\n",
    "        A.MedianBlur(p = 0.2),\n",
    "    ]),\n",
    "    album.ShiftScaleRotate(p = 0.3),\n",
    "    album.RGBShift(p = 0.4),\n",
    "    album.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "\n",
    "    def __init__(self,path,train_tfm = train_tfm, \n",
    "    test_tfm = test_tfm,files = None, mode = 'train'):\n",
    "        super(FoodDataset).__init__()\n",
    "        self.path = path\n",
    "        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n",
    "        if files != None:\n",
    "            self.files = files\n",
    "        print(f\"One {path} sample\",self.files[0])\n",
    "        self.train_transform = train_tfm\n",
    "        self.test_transform = test_tfm\n",
    "        self.mode = mode\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        fname = self.files[idx]\n",
    "        im = cv2.imread(fname)\n",
    "        \n",
    "        #im = self.data[idx]\n",
    "\n",
    "        # ref: https://github.com/Aentations-team/Aentations\n",
    "        train_im = self.train_transform(image=im)['image']\n",
    "        try:\n",
    "            label = int(fname.split(\"\\\\\")[-1].split(\"_\")[0])\n",
    "        except:\n",
    "            label = -1 # test has no label\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            return train_im, label\n",
    "        else:\n",
    "            test_im = self.test_transform(image=im)['image']\n",
    "            train_ims = [train_im]\n",
    "            for i in range(4):\n",
    "                train_ims.append(self.train_transform(image=im)['image'])\n",
    "            return train_ims, test_im, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "_dataset_dir = \"./food11\"\n",
    "# Construct datasets.\n",
    "# The argument \"loader\" tells how torchvision reads the data.\n",
    "train_set = FoodDataset(os.path.join(_dataset_dir,\"training\"), mode='train')\n",
    "valid_set = FoodDataset(os.path.join(_dataset_dir,\"validation\"), mode='train')\n",
    "concat = ConcatDataset([train_set, valid_set])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://github.com/facebookresearch/mixup-cifar10/blob/main/train.py\n",
    "def mixup_data(x, y, alpha = 0.5):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "split = 4\n",
    "n_epochs = 100\n",
    "patience = 100\n",
    "\n",
    "folds = KFold(n_splits=split, shuffle=True)\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(folds.split(concat)):\n",
    "    train = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    valid = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    train_loader = DataLoader(concat,batch_size = batch_size, shuffle = False, sampler = train, pin_memory = True)\n",
    "    valid_loader = DataLoader(concat,batch_size = batch_size, shuffle = False, sampler = valid, pin_memory = True)\n",
    "\n",
    "    model = models.resnet34(pretrained = False, num_classes=5).to(device)\n",
    "    # model.apply(ResetWeight)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay = 0.0005)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 10)\n",
    "\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_accuracy = []\n",
    "        train_loss = []\n",
    "\n",
    "        for batch in train_loader:\n",
    "            imgs, labels = batch\n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(imgs, labels, alpha = 0.4)\n",
    "            inputs, targets_a, targets_b = map(Variable, (inputs, targets_a, targets_b))\n",
    "\n",
    "            logits = model(inputs)\n",
    "            loss = mixup_criterion(criterion, logits, targets_a, targets_b, lam)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm = 5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "            train_loss.append(loss.item())\n",
    "            train_accuracy.append(acc)\n",
    "        \n",
    "        scheduler.step()\n",
    "        train_acc = sum(train_accuracy) / len(train_accuracy)\n",
    "        train_loss = sum(train_loss) / len(train_loss)\n",
    "\n",
    "        print(f\"Fold: {fold} [ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "        model.eval()\n",
    "        \n",
    "        valid_accuracy = []\n",
    "        valid_loss = []\n",
    "\n",
    "        for batch in valid_loader:\n",
    "            test_im, labels = batch\n",
    "            with torch.no_grad():\n",
    "                logits = model(test_im.to(device))\n",
    "            loss = criterion(logits, labels.to(device))\n",
    "            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "            valid_loss.append(loss.item())\n",
    "            valid_accuracy.append(acc)\n",
    "        \n",
    "        valid_acc = sum(valid_accuracy) / len(valid_accuracy)\n",
    "        valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "        print(f\"Fold: {fold} [ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "        if valid_acc > best_accuracy:\n",
    "            print(f\"Best model found at epoch {epoch}, saving model\")\n",
    "            torch.save(model.state_dict(), f\"./models/{_exp_name}_fold_{fold}.ckpt\")\n",
    "            best_accuracy = valid_acc\n",
    "            stale = 0\n",
    "        else:\n",
    "            stale += 1\n",
    "            if stale > patience:\n",
    "                print(f\"No improvment {patience} consecutive epochs, early stopping\")\n",
    "                break\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del train_loader, valid_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), mode='test')\n",
    "test_loader = DataLoader(test_set, batch_size = batch_size, shuffle = False, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TTA(model, train_ims, test_im):\n",
    "    test_pred = model(test_im.to(device))\n",
    "    train_pred = []\n",
    "    for im in train_ims:\n",
    "        train_pred.append(model(im.to(device)))\n",
    "\n",
    "    avg = sum(train_pred) / len(train_pred)\n",
    "    return avg * 0.5 + test_pred * 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []\n",
    "for fold in range(split):\n",
    "    pred = []\n",
    "    best_model = models.resnet34(pretrained = False, num_classes = 5).to(device)\n",
    "    best_model.load_state_dict(torch.load(f\"./models/{_exp_name}_fold_{fold}.ckpt\"))\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for train_im, test_im, i in test_loader:\n",
    "            test_pred = TTA(best_model, train_im, test_im)\n",
    "            pred.append(test_pred)\n",
    "    predict.append(torch.cat(pred))\n",
    "\n",
    "mixpred = torch.stack(predict, dim = 0).sum(dim = 0) / split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "test_label = np.argmax(mixpred.cpu().data.numpy(), axis = 1)\n",
    "prediction += test_label.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test csv\n",
    "def pad4(i):\n",
    "    return \"0\"*(4-len(str(i)))+str(i)\n",
    "df = pd.DataFrame()\n",
    "df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n",
    "df[\"Category\"] = prediction\n",
    "name = 'predict.csv'\n",
    "df.to_csv(name,index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "663051497cc4aed5e2d10b0385c58c8517c7eb37ecbb3faa064a1d3580a6d77a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
